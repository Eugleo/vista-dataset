models:
# - async_batch: false
#   is_one_shot: true
#   kind: gpt
#   model: gpt-4o
#   n_frames: 16
# - async_batch: false
#   is_one_shot: false
#   kind: gpt
#   model: gpt-4o
#   n_frames: 16
# - async_batch: false
#   is_one_shot: false
#   kind: gpt
#   model: gpt-4o
#   n_frames: 5
- encoder: s3d
  heads:
  - kind: cosine
  kind: encoder
- encoder: viclip
  heads:
  - kind: cosine
  kind: encoder
# - encoder: clip
#   heads:
#   - kind: cosine
#   hf_model: ViT-bigG-14/laion2b_s39b_b160k
#   kind: encoder
#   n_frames: 4
- batch_size: 1
  encoder: clip
  heads:
  - kind: cosine
  hf_model: ViT-bigG-14/laion2b_s39b_b160k
  kind: encoder
  n_frames: 32
tasks:
- level_4/remix/remix_level_4_group_1
- level_8/remix/remix_level_8_group_3
- extrapyramidal/object_tracking/object_identity
- extrapyramidal/object_tracking/relative_position
task_dir: /data/datasets/vlm_benchmark/tasks/real_life
video_dir: /data/datasets/vlm_benchmark/real_life
cache_dir: /data/datasets/vlm_benchmark/.cache
output_dir: /data/datasets/vlm_benchmark/experiments/evan
